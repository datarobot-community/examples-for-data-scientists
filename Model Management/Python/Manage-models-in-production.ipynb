{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manage models in production\n",
    "\n",
    "This code example shows how to manage and monitor models deployed to production environments using DataRobot's Python client to accomplish various tasks: model deployment, replacement, deletion, and monitoring.\n",
    "\n",
    "Download this notebook from the [code examples home page](index).\n",
    "\n",
    "## Requirements\n",
    "\n",
    "* Python version 3.7.3+\n",
    "* DataRobot API version 2.19.0+\n",
    "* A DataRobot `Project` object\n",
    "* A DataRobot `Model` object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datarobot as dr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a deployment\n",
    "\n",
    "When creating a new deployment, you must provide a DataRobot model ID. The model ID represents a single instance of a model type, feature list, and sample size, used to differentiate models from the blueprint ID. The model ID is generated during Autopilot. Obtain the model ID from the UI by selecting the model to deploy from the Leaderboard and copying the string after `/models/` in the URL.\n",
    "\n",
    "A prediction server makes predictions against a deployment and is required for each deployment. Use the default prediction server unless you are an Enterprise user, in which case you should use a preconfigured prediction server instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of prediction servers\n",
    "prediction_server = dr.PredictionServer.list()[0]\n",
    "\n",
    "project = dr.Project.get('<project_id>') # Provide your project object here\n",
    "model = project.get_models()[0]\n",
    "\n",
    "# Create a deployment\n",
    "deployment = dr.Deployment.create_from_learning_model(\n",
    "    model.id, label='New Deployment', description='A new deployment',\n",
    "    default_prediction_server_id=prediction_server.id)\n",
    "deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List available deployments\n",
    "\n",
    "Use the following command to list all available deployments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deployments = dr.Deployment.list()\n",
    "deployments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can filter the returned deployments by passing an instance of the `DeploymentListFilters` class to the `filters` keyword argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = dr.models.deployment.DeploymentListFilters(\n",
    "    role='OWNER',\n",
    "    accuracy_health=dr.enums.DEPLOYMENT_ACCURACY_HEALTH_STATUS.FAILING\n",
    ")\n",
    "deployments = dr.Deployment.list(filters=filters)\n",
    "deployments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve a deployment\n",
    "\n",
    "Retrieve a specific deployment by specifying its [deployment ID](https://docs.datarobot.com/en/docs/predictions/predapi/dep-pred.html#predictions-for-deployments), rather than listing all deployments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment = dr.Deployment.get(deployment_id='<deployment_id>') # Provide your own deployment ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update a deployment\n",
    "\n",
    "Use the command below to update the label and description for a deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment = dr.Deployment.get(deployment_id='<deployment_id>') # Provide your own deployment ID\n",
    "deployment.update(label='New label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete a deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment = dr.Deployment.get(deployment_id='<deployment_id>') # Provide your own deployment ID\n",
    "deployment.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model replacement\n",
    "\n",
    "You can replace a deployment's model without interrupting predictions. Model replacement is an asynchronous process which requires prepatory steps to complete the process. However, predictions made against the deployment will use the new model as soon as you initiate the replacement process. Note that the <code>replace_model()</code> function will not return until this process is fully completed.\n",
    "\n",
    "Alongside the new model's model ID, you must provide a reason for replacement, stored in the model history of the deployment for auditing purposes. An enum, <code>MODEL_REPLACEMENT_REASON</code>, is provided for this purpose, and all possible values are listed below:\n",
    "\n",
    "- MODEL_REPLACEMENT_REASON.ACCURACY\n",
    "- MODEL_REPLACEMENT_REASON.DATA_DRIFT\n",
    "- MODEL_REPLACEMENT_REASON.ERRORS\n",
    "- MODEL_REPLACEMENT_REASON.SCHEDULED_REFRESH\n",
    "- MODEL_REPLACEMENT_REASON.SCORING_SPEED\n",
    "- MODEL_REPLACEMENT_REASON.OTHER\n",
    "\n",
    "The code below demonstrates an example of model replacement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datarobot.enums import MODEL_REPLACEMENT_REASON\n",
    "\n",
    "deployment=deployment.get(deployment_id='<deployment_id>') # Provide your own deployment ID\n",
    "deployment.model['id'], deployment.model['type']\n",
    "\n",
    "deployment.replace_model('<deployment_id>', MODEL_REPLACEMENT_REASON.ACCURACY) #Provide the new model ID\n",
    "deployment.model['id'], deployment.model['type']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model validation (pre-replacement)\n",
    "\n",
    "Before initiating a model replacement request, DataRobot recommends using the <code>validate_replacement_model()</code> function to verify if the new model can be used as a replacement.\n",
    "\n",
    "The <code>validate_replacement_model()</code> function returns the validation status, a message, and a checks dictionary. If the status is `passing` or `warning`, use <code>replace_model()</code> to replace the model. If the status is <code>failing</code>, refer to the checks dictionary for information as to why the new model cannot be used as a replacement.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment = dr.Deployment.get(deployment_id='<deployment_id>')\n",
    "status, message, checks = deployment.validate_replacement_model(new_model_id=model.id)\n",
    "status\n",
    "\n",
    "# `checks` can be inspected for detail, showing two examples here:\n",
    "checks['target']\n",
    "checks['permission']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model monitoring\n",
    "\n",
    "Deployment monitoring can be summarized by its three major components: [service health](https://docs.datarobot.com/en/docs/mlops/monitor/service-health.html), [data drift](https://docs.datarobot.com/en/docs/mlops/monitor/data-drift.html#data-drift-tab), and [accuracy](https://docs.datarobot.com/en/docs/mlops/monitor/deploy-accuracy.html). For a Deployment object, DataRobot provides `get` functions that allows you to query all of the monitoring data. Alternatively, you can retrieve monitoring data directly using a deployment ID.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datarobot.models import Deployment, ServiceStats\n",
    "\n",
    "deployment_id = '<deployment_id>'\n",
    "\n",
    "# call `get` functions on a `Deployment` object\n",
    "deployment = Deployment.get(deployment_id)\n",
    "service_stats = deployment.get_service_stats()\n",
    "\n",
    "# directly fetch without a `Deployment` object\n",
    "service_stats = ServiceStats.get(deployment_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When querying monitoring data, you can optionally provide a start and end time. DataRobot accepts either a datetime object or a string. Note that only top of the hour datetimes are accepted, for example: `2019-08-01T00:00:00Z`. By default, the end time of the query will be the next top of the hour, and the start time will be 7 days before the end time.\n",
    "\n",
    "In the \"over time\" variants, an optional `bucket_size` can be provided to specify the resolution of time buckets. For example, if the start time is `2019-08-01T00:00:00Z`, then the end time is `2019-08-02T00:00:00Z` and the `bucket_size` is `T1H`. In this case 24 time buckets are generated, each providing data calculated over one hour. Use `construct_duration_string()` to help construct a bucket size string."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Service health\n",
    "\n",
    "Service health metrics capture a deploymentâ€™s ability to respond to prediction requests quickly and reliably. This helps identify bottlenecks and assess capacity, which is critical to proper provisioning. Use `SERVICE_STAT_METRIC.ALL` to retrieve a list of supported metrics.\n",
    "\n",
    "`ServiceStats` retrieves values for all service stats metrics; `ServiceStatsOverTime` can be used to fetch how one single metric changes over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from datarobot.enums import SERVICE_STAT_METRIC\n",
    "from datarobot.helpers.partitioning_methods import construct_duration_string\n",
    "from datarobot.models import Deployment\n",
    "\n",
    "deployment = Deployment.get(deployment_id='<deployment_id>')\n",
    "service_stats = deployment.get_service_stats(\n",
    "    start_time=datetime(2019, 8, 1, hour=15),\n",
    "    end_time=datetime(2019, 8, 8, hour=15)\n",
    ")\n",
    "service_stats[SERVICE_STAT_METRIC.TOTAL_PREDICTIONS]\n",
    "\n",
    "total_predictions = deployment.get_service_stats_over_time(\n",
    "    start_time=datetime(2019, 8, 1, hour=15),\n",
    "    end_time=datetime(2019, 8, 8, hour=15),\n",
    "    bucket_size=construct_duration_string(days=1),\n",
    "    metric=SERVICE_STAT_METRIC.TOTAL_PREDICTIONS\n",
    ")\n",
    "total_predictions.bucket_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data drift\n",
    "\n",
    "As training and production data change over time, a deployed model loses predictive power. The data surrounding the model is said to be drifting. By leveraging the training data and prediction data (also known as inference data) that is added to your deployment, data drift helps you to analyze a model's performance after it has been deployed.\n",
    "\n",
    "Deploymentâ€™s target drift and feature drift can be retrieved separately using `datarobot.models.TargetDrift` and `datarobot.models.FeatureDrift`. Use `DATA_DRIFT_METRIC.ALL` to retrieve a list of supported metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from datarobot.enums import DATA_DRIFT_METRIC\n",
    "from datarobot.models import Deployment, FeatureDrift\n",
    "\n",
    "deployment = Deployment.get(deployment_id='<deployment_id>')\n",
    "target_drift = deployment.get_target_drift(\n",
    "    start_time=datetime(2019, 8, 1, hour=15),\n",
    "    end_time=datetime(2019, 8, 8, hour=15)\n",
    ")\n",
    "feature_drift_data = FeatureDrift.list(\n",
    "    deployment_id='<deployment_id>',\n",
    "    start_time=datetime(2019, 8, 1, hour=15),\n",
    "    end_time=datetime(2019, 8, 8, hour=15),\n",
    "    metric=DATA_DRIFT_METRIC.HELLINGER\n",
    ")\n",
    "feature_drift = feature_drift_data[0]\n",
    "feature_drift.name\n",
    "feature_drift.drift_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Accuracy\n",
    "\n",
    "Accuracy metrics help determine whether a model's quality is decaying and if you should consider replacing it. A collection of metrics are provided to measure the accuracy of a deploymentâ€™s predictions. For deployments with classification models, use `ACCURACY_METRIC.ALL_CLASSIFICATION` for all supported metrics. For deployments with regression models, use `ACCURACY_METRIC.ALL_REGRESSION` instead.\n",
    "\n",
    "`Accuracy` and `AccuracyOverTime` are provided to retrieve all default accuracy metrics and how one single metric change over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from datarobot.enums import ACCURACY_METRIC\n",
    "from datarobot.helpers.partitioning_methods import construct_duration_string\n",
    "from datarobot.models import Deployment\n",
    "\n",
    "deployment = Deployment.get(deployment_id='<deployment_id>')\n",
    "accuracy = deployment.get_accuracy(\n",
    "    start_time=datetime(2021, 8, 1, hour=15),\n",
    "    end_time=datetime(2021, 8, 1, 15, 0)\n",
    ")\n",
    "accuracy[ACCURACY_METRIC.RMSE]\n",
    "\n",
    "rmse = deployment.get_accuracy_over_time(\n",
    "    start_time=datetime(2021, 12, 1),\n",
    "    end_time=datetime(2021, 12, 3),\n",
    "    bucket_size=construct_duration_string(days=1),\n",
    "    metric=ACCURACY_METRIC.RMSE\n",
    ")\n",
    "rmse.bucket_values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
